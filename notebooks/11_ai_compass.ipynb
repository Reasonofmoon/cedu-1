{
  "nbformat": 4, "nbformat_minor": 0,
  "metadata": {"colab": {"provenance": [], "toc_visible": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}},
  "cells": [
    {"cell_type": "markdown", "source": ["# π§­ 11κ°•: AI μ—­λ‰ μ§„λ‹¨ & μ„±μ¥\n", "\n", "> 30λ¬Έν•­ μκΈ°μ§„λ‹¨ β†’ λ μ΄λ” μ°¨νΈ μ‹κ°ν™” β†’ 90μΌ μ„±μ¥ λ΅λ“λ§µ μλ™ μƒμ„±"], "metadata": {}},
    {"cell_type": "code", "source": ["!pip install -q google-genai matplotlib numpy\nfrom google import genai\nfrom google.colab import userdata\nimport getpass, numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams['font.family'] = 'DejaVu Sans'\n\ntry:\n    API_KEY = userdata.get('GEMINI_API_KEY')\nexcept:\n    API_KEY = getpass.getpass('π”‘ Gemini API Key: ')\n\nclient = genai.Client(api_key=API_KEY)\nMODEL = 'gemini-2.5-flash'\nprint('β… μ¤€λΉ„ μ™„λ£!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## π”¬ μ‹¤μµ 1: 30λ¬Έν•­ μκΈ° μ§„λ‹¨ μƒμ„±"], "metadata": {}},
    {"cell_type": "code", "source": ["prompt1 = \"\"\"\nλ„λ” AI κµμ΅ μ „λ¬Έκ°€μ΄μ μ—­λ‰ μ§„λ‹¨ μ„¤κ³„μ‚¬μ•Ό.\n\nν•™μ› μ›μ¥μ AI μ—­λ‰μ„ μ§„λ‹¨ν•λ” μ„¤λ¬Έμ§€λ¥Ό λ§λ“¤μ–΄μ¤.\n6κ° μμ—­, κ° 5λ¬Έν•­, μ΄ 30λ¬Έν•­.\n\nμμ—­: ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ / AI λ„κµ¬ ν™μ© / λ°μ΄ν„° λ¶„μ„ /\nμλ™ν™” μ„¤κ³„ / μ½ν…μΈ  μ μ‘ / μ „λµμ  μ‚¬κ³ \n\nκ° λ¬Έν•­:\nQ. [κµ¬μ²΄μ  μƒν™© μ§λ¬Έ]\nβ‘  μ „ν€ λ»ν•λ‹¤ (1μ )\nβ‘΅ λ„μ›€ μμΌλ©΄ κ°€λ¥ (2μ )\nβ‘Ά νΌμ ν•  μ μλ‹¤ (3μ )\nβ‘£ λ‚¨μ„ κ°€λ¥΄μΉ  μ μλ‹¤ (4μ )\n\nν•™μ› μ—…λ¬΄ μ—°κ²° κµ¬μ²΄μ  λ¬Έν•­μΌλ΅.\n\"\"\"\n\nresponse = client.models.generate_content(model=MODEL, contents=prompt1)\nsurvey = response.text\nprint('π“‹ AI μ—­λ‰ μκΈ° μ§„λ‹¨ (30λ¬Έν•­)')\nprint('='*50)\nprint(survey)"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## π”¬ μ‹¤μµ 2: λ μ΄λ” μ°¨νΈ μƒμ„±\n", "\n", "> μ•„λ μ μλ¥Ό μμ •ν• ν›„ μ‹¤ν–‰ν•μ„Έμ”!"], "metadata": {}},
    {"cell_type": "code", "source": ["# βοΈ μ—¬λ¬λ¶„μ μ§„λ‹¨ μ μλ¥Ό μ…λ ¥ν•μ„Έμ”! (μµμ† 5, μµλ€ 20)\nmy_scores = {\n    'Prompt': 14,        # β† ν”„λ΅¬ν”„νΈ μμ—­ μ μ μ…λ ¥\n    'Tools': 16,         # β† AI λ„κµ¬ μμ—­ μ μ μ…λ ¥\n    'Data': 8,           # β† λ°μ΄ν„° λ¶„μ„ μ μ μ…λ ¥\n    'Automation': 6,     # β† μλ™ν™” μ„¤κ³„ μ μ μ…λ ¥\n    'Content': 18,       # β† μ½ν…μΈ  μ μ‘ μ μ μ…λ ¥\n    'Strategy': 10       # β† μ „λµμ  μ‚¬κ³  μ μ μ…λ ¥\n}\n\ntotal = sum(my_scores.values())\nif total <= 48:\n    level = 'Lv.1 π± μΈμ‹μ'\nelif total <= 72:\n    level = 'Lv.2 πΏ ν™μ©μ'\nelif total <= 96:\n    level = 'Lv.3 π³ μ„¤κ³„μ'\nelse:\n    level = 'Lv.4 π”οΈ μ „λµκ°€'\n\nprint(f'π“ μ΄μ : {total}/120')\nprint(f'π― λ λ²¨: {level}')\nprint(f'π’ κ°€μ¥ κ°•ν• μμ—­: {max(my_scores, key=my_scores.get)}')\nprint(f'π“ κ°μ„  ν•„μ” μμ—­: {min(my_scores, key=my_scores.get)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# π“ λ μ΄λ” μ°¨νΈ μƒμ„±\ncategories = list(my_scores.keys())\nvalues = list(my_scores.values())\n\n# λ‹«κΈ° μ„ν•΄ μ²« κ°’ μ¶”κ°€\ncategories_closed = categories + [categories[0]]\nvalues_closed = values + [values[0]]\nmax_val = 20\n\nangles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\nangles += angles[:1]\n\nfig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n\n# λ©ν‘μ„  (λ§μ )\nax.plot(angles, [max_val] * len(angles), 'b--', alpha=0.2, label='Max (20)')\nax.fill(angles, [max_val] * len(angles), alpha=0.05, color='blue')\n\n# λ‚΄ μ μ\nax.plot(angles, values_closed, 'o-', linewidth=2, color='#FF6B6B', label='My Score')\nax.fill(angles, values_closed, alpha=0.25, color='#FF6B6B')\n\nax.set_xticks(angles[:-1])\nax.set_xticklabels(categories, size=12, fontweight='bold')\nax.set_ylim(0, max_val)\nax.set_title(f'AI Competency Radar\\nTotal: {total}/120 | {level}',\n             size=16, fontweight='bold', pad=20)\nax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n\nplt.tight_layout()\nplt.savefig('ai_radar.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint('π“ λ μ΄λ” μ°¨νΈ μƒμ„± μ™„λ£!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## π”¬ μ‹¤μµ 3: 90μΌ μ„±μ¥ λ΅λ“λ§µ"], "metadata": {}},
    {"cell_type": "code", "source": ["weakest = min(my_scores, key=my_scores.get)\nstrongest = max(my_scores, key=my_scores.get)\n\nprompt3 = f\"\"\"\nλ„λ” AI ν•™μµ μ„¤κ³„ μ½”μΉμ•Ό.\n\nμ•„λ μ—­λ‰ μ§„λ‹¨ κ²°κ³Όλ¥Ό λ°”νƒ•μΌλ΅ 90μΌ AI μ„±μ¥ λ΅λ“λ§µμ„ μ‘μ„±ν•΄μ¤.\n\nμ§„λ‹¨ κ²°κ³Ό:\n- μ „μ²΄ λ λ²¨: {level}\n- μ΄μ : {total}/120\n- κ°€μ¥ μ•½ν• μμ—­: {weakest} ({my_scores[weakest]}μ )\n- κ°€μ¥ κ°•ν• μμ—­: {strongest} ({my_scores[strongest]}μ )\n- μ „μ²΄ μ μ: {my_scores}\n\n| κΈ°κ°„ | λ©ν‘ | ν•™μµ λ‚΄μ© | μ‹¤μµ κ³Όμ  | ν™•μΈ λ°©λ²• |\n|---|---|---|---|---|\n| 1~30μΌ | μ•½ν• μμ—­ λ³΄κ°• | ... | ... | ... |\n| 31~60μΌ | μ¤‘κ°„ μμ—­ κ°•ν™” | ... | ... | ... |\n| 61~90μΌ | ν†µν•© μ‹¤μ „ | ... | ... | ... |\n\nν•λ£¨ 30λ¶„ μ΄λ‚΄. μ•½ν• μμ—­ λ¨Όμ € λ³΄κ°•.\n90μΌ ν›„ λ©ν‘ μ μ μ„¤μ •.\n\"\"\"\n\nresponse = client.models.generate_content(model=MODEL, contents=prompt3)\nroadmap = response.text\nprint('π—ΊοΈ 90μΌ μ„±μ¥ λ΅λ“λ§µ')\nprint('='*50)\nprint(roadmap)"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# π’Ύ μ €μ¥\noutput = f\"μ§„λ‹¨κ²°κ³Ό: {level} ({total}/120)\\n{my_scores}\\n\\nλ΅λ“λ§µ:\\n{roadmap}\"\nwith open('AIμ—­λ‰_μ§„λ‹¨κ²°κ³Ό.txt', 'w', encoding='utf-8') as f:\n    f.write(output)\nfrom google.colab import files\nfiles.download('AIμ—­λ‰_μ§„λ‹¨κ²°κ³Ό.txt')\nfiles.download('ai_radar.png')\nprint('β… λ‹¤μ΄λ΅λ“!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## π† 11κ°• μ™„λ£!\n", "π‘‰ [12κ°•: ν†µν•© λ€μ‹λ³΄λ“](https://colab.research.google.com/github/Reasonofmoon/cedu-1/blob/main/notebooks/12_cockpit.ipynb)"], "metadata": {}}
  ]
}
