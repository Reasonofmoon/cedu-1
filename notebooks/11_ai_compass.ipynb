{
  "nbformat": 4, "nbformat_minor": 0,
  "metadata": {"colab": {"provenance": [], "toc_visible": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}},
  "cells": [
    {"cell_type": "markdown", "source": ["# ğŸ§­ 11ê°•: AI ì—­ëŸ‰ ì§„ë‹¨ & ì„±ì¥\n", "\n", "> 30ë¬¸í•­ ìê¸°ì§„ë‹¨ â†’ ë ˆì´ë” ì°¨íŠ¸ ì‹œê°í™” â†’ 90ì¼ ì„±ì¥ ë¡œë“œë§µ ìë™ ìƒì„±"], "metadata": {}},
    {"cell_type": "code", "source": ["# âš™ï¸ í™˜ê²½ ì„¤ì •\n!pip install -q -U google-genai\n\nfrom google import genai\nfrom google.colab import userdata\nimport getpass\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams['font.family'] = 'DejaVu Sans'\n\ntry:\n    api_key = userdata.get('GEMINI_API_KEY')\n    if isinstance(api_key, dict):\n        api_key = str(list(api_key.values())[0])\n    API_KEY = str(api_key).strip()\nexcept Exception:\n    API_KEY = getpass.getpass('ğŸ”‘ Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: ')\n\nclient = genai.Client(api_key=API_KEY)\nMODEL = 'gemini-2.5-flash'\nprint('âœ… ì¤€ë¹„ ì™„ë£Œ!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## ğŸ”¬ ì‹¤ìŠµ 1: 30ë¬¸í•­ ìê¸° ì§„ë‹¨ ìƒì„±"], "metadata": {}},
    {"cell_type": "code", "source": ["prompt1 = \"\"\"\në„ˆëŠ” AI êµìœ¡ ì „ë¬¸ê°€ì´ì ì—­ëŸ‰ ì§„ë‹¨ ì„¤ê³„ì‚¬ì•¼.\n\ní•™ì› ì›ì¥ì˜ AI ì—­ëŸ‰ì„ ì§„ë‹¨í•˜ëŠ” ì„¤ë¬¸ì§€ë¥¼ ë§Œë“¤ì–´ì¤˜.\n6ê°œ ì˜ì—­, ê° 5ë¬¸í•­, ì´ 30ë¬¸í•­.\n\nì˜ì—­: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ / AI ë„êµ¬ í™œìš© / ë°ì´í„° ë¶„ì„ /\nìë™í™” ì„¤ê³„ / ì½˜í…ì¸  ì œì‘ / ì „ëµì  ì‚¬ê³ \n\nê° ë¬¸í•­:\nQ. [êµ¬ì²´ì  ìƒí™© ì§ˆë¬¸]\n1) ì „í˜€ ëª»í•œë‹¤ (1ì )\n2) ë„ì›€ ìˆìœ¼ë©´ ê°€ëŠ¥ (2ì )\n3) í˜¼ì í•  ìˆ˜ ìˆë‹¤ (3ì )\n4) ë‚¨ì„ ê°€ë¥´ì¹  ìˆ˜ ìˆë‹¤ (4ì )\n\ní•™ì› ì—…ë¬´ ì—°ê²° êµ¬ì²´ì  ë¬¸í•­ìœ¼ë¡œ.\n\"\"\"\n\nresponse = client.models.generate_content(model=MODEL, contents=prompt1)\nsurvey = response.text\nprint('ğŸ“‹ AI ì—­ëŸ‰ ìê¸° ì§„ë‹¨ (30ë¬¸í•­)')\nprint('='*50)\nprint(survey)"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## ğŸ”¬ ì‹¤ìŠµ 2: ë ˆì´ë” ì°¨íŠ¸ ìƒì„±\n", "\n", "> ì•„ë˜ ì ìˆ˜ë¥¼ ìˆ˜ì •í•œ í›„ ì‹¤í–‰í•˜ì„¸ìš”!"], "metadata": {}},
    {"cell_type": "code", "source": ["# âœï¸ ì—¬ëŸ¬ë¶„ì˜ ì§„ë‹¨ ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”! (ìµœì†Œ 5, ìµœëŒ€ 20)\nmy_scores = {\n    'Prompt': 14,\n    'Tools': 16,\n    'Data': 8,\n    'Automation': 6,\n    'Content': 18,\n    'Strategy': 10\n}\n\ntotal = sum(my_scores.values())\nif total <= 48:\n    level = 'Lv.1 ğŸŒ± ì¸ì‹ì'\nelif total <= 72:\n    level = 'Lv.2 ğŸŒ¿ í™œìš©ì'\nelif total <= 96:\n    level = 'Lv.3 ğŸŒ³ ì„¤ê³„ì'\nelse:\n    level = 'Lv.4 ğŸ”ï¸ ì „ëµê°€'\n\nprint(f'ğŸ“Š ì´ì : {total}/120')\nprint(f'ğŸ¯ ë ˆë²¨: {level}')\nprint(f'ğŸ’ª ê°€ì¥ ê°•í•œ ì˜ì—­: {max(my_scores, key=my_scores.get)}')\nprint(f'ğŸ“ˆ ê°œì„  í•„ìš” ì˜ì—­: {min(my_scores, key=my_scores.get)}')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# ğŸ“Š ë ˆì´ë” ì°¨íŠ¸\ncategories = list(my_scores.keys())\nvalues = list(my_scores.values())\nmax_val = 20\n\nangles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\nangles += angles[:1]\nvalues_closed = values + [values[0]]\n\nfig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n\nax.plot(angles, [max_val] * len(angles), 'b--', alpha=0.2, label='Max (20)')\nax.fill(angles, [max_val] * len(angles), alpha=0.05, color='blue')\nax.plot(angles, values_closed, 'o-', linewidth=2, color='#FF6B6B', label='My Score')\nax.fill(angles, values_closed, alpha=0.25, color='#FF6B6B')\n\nax.set_xticks(angles[:-1])\nax.set_xticklabels(categories, size=12, fontweight='bold')\nax.set_ylim(0, max_val)\nax.set_title(f'AI Competency Radar\\nTotal: {total}/120 | {level}',\n             size=16, fontweight='bold', pad=20)\nax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n\nplt.tight_layout()\nplt.savefig('ai_radar.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint('ğŸ“Š ë ˆì´ë” ì°¨íŠ¸ ì €ì¥ ì™„ë£Œ!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## ğŸ”¬ ì‹¤ìŠµ 3: 90ì¼ ì„±ì¥ ë¡œë“œë§µ"], "metadata": {}},
    {"cell_type": "code", "source": ["weakest = min(my_scores, key=my_scores.get)\nstrongest = max(my_scores, key=my_scores.get)\n\nprompt3 = f\"\"\"\në„ˆëŠ” AI í•™ìŠµ ì„¤ê³„ ì½”ì¹˜ì•¼.\n\nì•„ë˜ ì—­ëŸ‰ ì§„ë‹¨ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 90ì¼ AI ì„±ì¥ ë¡œë“œë§µì„ ì‘ì„±í•´ì¤˜.\n\nì§„ë‹¨ ê²°ê³¼:\n- ì „ì²´ ë ˆë²¨: {level}\n- ì´ì : {total}/120\n- ê°€ì¥ ì•½í•œ ì˜ì—­: {weakest} ({my_scores[weakest]}ì )\n- ê°€ì¥ ê°•í•œ ì˜ì—­: {strongest} ({my_scores[strongest]}ì )\n- ì „ì²´ ì ìˆ˜: {my_scores}\n\n| ê¸°ê°„ | ëª©í‘œ | í•™ìŠµ ë‚´ìš© | ì‹¤ìŠµ ê³¼ì œ | í™•ì¸ ë°©ë²• |\n|---|---|---|---|---|\n| 1~30ì¼ | ì•½í•œ ì˜ì—­ ë³´ê°• | ... | ... | ... |\n| 31~60ì¼ | ì¤‘ê°„ ì˜ì—­ ê°•í™” | ... | ... | ... |\n| 61~90ì¼ | í†µí•© ì‹¤ì „ | ... | ... | ... |\n\ní•˜ë£¨ 30ë¶„ ì´ë‚´. ì•½í•œ ì˜ì—­ ë¨¼ì € ë³´ê°•.\n90ì¼ í›„ ëª©í‘œ ì ìˆ˜ ì„¤ì •.\n\"\"\"\n\nresponse = client.models.generate_content(model=MODEL, contents=prompt3)\nroadmap = response.text\nprint('ğŸ—ºï¸ 90ì¼ ì„±ì¥ ë¡œë“œë§µ')\nprint('='*50)\nprint(roadmap)"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "code", "source": ["# ğŸ’¾ ì €ì¥\noutput = f\"ì§„ë‹¨ê²°ê³¼: {level} ({total}/120)\\n{my_scores}\\n\\në¡œë“œë§µ:\\n{roadmap}\"\nwith open('AIì—­ëŸ‰_ì§„ë‹¨ê²°ê³¼.txt', 'w', encoding='utf-8') as f:\n    f.write(output)\nfrom google.colab import files\nfiles.download('AIì—­ëŸ‰_ì§„ë‹¨ê²°ê³¼.txt')\nfiles.download('ai_radar.png')\nprint('âœ… ë‹¤ìš´ë¡œë“œ!')"], "metadata": {}, "execution_count": null, "outputs": []},
    {"cell_type": "markdown", "source": ["## ğŸ† 11ê°• ì™„ë£Œ!\n", "ğŸ‘‰ [12ê°•: í†µí•© ëŒ€ì‹œë³´ë“œ](https://colab.research.google.com/github/Reasonofmoon/cedu-1/blob/main/notebooks/12_cockpit.ipynb)"], "metadata": {}}
  ]
}
